name: ‚è±Ô∏è Hourly AQI Data Pipeline

on:
  schedule:
    - cron: "0 * * * *"  # Every hour
  workflow_dispatch:     # manual trigger for testing

jobs:
  fetch-and-process:
    runs-on: ubuntu-latest

    steps:
      - name: üì¶ Checkout Repository
        uses: actions/checkout@v4

      - name: üêç Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.10"

      - name: ‚öôÔ∏è Install and Run Fetch Script
        env:
          HOPSWORKS_API_KEY: ${{ secrets.HOPSWORKS_API_KEY }}
          HOPSWORKS_PROJECT: ${{ secrets.HOPSWORKS_PROJECT }}
          LAT: ${{ secrets.LAT }}
          LON: ${{ secrets.LON }}
        run: |
          echo "Upgrading pip..."
          pip install --upgrade pip

          echo "Installing dependencies..."
          pip install hopsworks[python]==4.2.2 hsfs==4.2.2 confluent-kafka python-dotenv
          pip install --no-cache-dir -r requirements.txt

          echo "Force reinstalling dotenv..."
          pip install --no-cache-dir --upgrade python-dotenv

          echo "Checking installed packages..."
          pip show python-dotenv || echo "python-dotenv missing!"
          python -m pip freeze | grep dotenv || echo "dotenv not found!"

          echo "Running fetch script..."
          python src/features/fetch_raw_data.py

      - name: üîß Process and Engineer Features
        env:
          HOPSWORKS_API_KEY: ${{ secrets.HOPSWORKS_API_KEY }}
          HOPSWORKS_PROJECT: ${{ secrets.HOPSWORKS_PROJECT }}
        run: |
          python src/features/process_features.py
